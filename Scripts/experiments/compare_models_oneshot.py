"""
# æ–‡ä»¶è¯´æ˜ï¼ˆexperiments/compare_models_oneshot.pyï¼‰

- **æ–‡ä»¶ä½œç”¨**ï¼šåœ¨å•ä¸ªç¼ºé™· Patch ä¸Šï¼Œå¯¹æ¯” CLIP ä¸ DINOv2 çš„ç›¸ä¼¼åº¦è¡¨ç°ï¼Œç›´è§‚æ„Ÿå—ä¸¤è€…å¯¹ç»†å°ç¼ºé™·çš„æ•æ„Ÿåº¦å·®å¼‚ã€‚
- **è¿è¡Œæ–¹å¼**ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ `python Scripts/experiments/compare_models_oneshot.py`ï¼Œå¯æŒ‰éœ€ä¿®æ”¹å›¾ç‰‡è·¯å¾„å’Œè£å‰ªåæ ‡ã€‚
- **è¾“å‡ºç»“æœ**ï¼šåœ¨ç»ˆç«¯æ‰“å°ä¸¤ç§æ¨¡å‹çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼Œå¹¶ç”Ÿæˆ `comparison_visual.png` æ–¹ä¾¿è‚‰çœ¼æŸ¥çœ‹ Patch å·®å¼‚ã€‚
- **åˆ†ç±»è§’è‰²**ï¼šå½’å±äº `experiments` åˆ†ç±»ï¼Œæ˜¯ç”¨äºåˆ†æä¸å±•ç¤ºæ¨¡å‹ç‰¹æ€§çš„å¿«é€Ÿå¯¹æ¯”è„šæœ¬ã€‚
"""

import torch
import clip
import torchvision.transforms as T
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os

# --- é…ç½® ---
# 1. ä½ çš„æµ‹è¯•å›¾ (æœ‰ç¼ºé™·)
TEST_IMG_PATH = "/data/XL/å¤šæ¨¡æ€RAG/DataSet/MVTec-AD/bottle/test/broken_large/000.png" 
# 2. æ‰¾ä¸€å¼ æ­£å¸¸å›¾åšå¯¹æ¯” (éšä¾¿æ‰¾ä¸€å¼  train/good é‡Œçš„)
NORMAL_IMG_PATH = "/data/XL/å¤šæ¨¡æ€RAG/DataSet/MVTec-AD/bottle/train/good/000.png" 

# 3. å…³æ³¨çš„åæ ‡ (ç¼ºé™·ä½ç½®)
CROP_X, CROP_Y = 200, 200  
PATCH_SIZE = 224 # Patch å¤§å°

class ModelComparator:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"âš™ï¸ Device: {self.device}")
        
        # --- åŠ è½½ CLIP ---
        print("ğŸš€ Loading CLIP (ViT-L/14@336px)...")
        self.clip_model, self.clip_preprocess = clip.load("ViT-L/14@336px", device=self.device)
        self.clip_model.eval()

        # --- åŠ è½½ DINOv2 ---
        print("ğŸ¦• Loading DINOv2 (ViT-L/14)...")
        self.dino_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitl14')
        self.dino_model.to(self.device)
        self.dino_model.eval()
        
        # DINOv2 é¢„å¤„ç†
        self.dino_preprocess = T.Compose([
            T.Resize((224, 224), interpolation=T.InterpolationMode.BICUBIC),
            T.ToTensor(),
            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def get_feature(self, img_pil, model_name):
        """æå–ç‰¹å¾å¹¶å½’ä¸€åŒ–"""
        with torch.no_grad():
            if model_name == 'clip':
                tensor = self.clip_preprocess(img_pil).unsqueeze(0).to(self.device)
                feat = self.clip_model.encode_image(tensor)
            else:
                tensor = self.dino_preprocess(img_pil).unsqueeze(0).to(self.device)
                feat = self.dino_model(tensor)
            
            # L2 å½’ä¸€åŒ– (å…³é”®!)
            feat /= feat.norm(dim=-1, keepdim=True)
        return feat.cpu().numpy()[0]

    def run_comparison(self):
        if not os.path.exists(TEST_IMG_PATH) or not os.path.exists(NORMAL_IMG_PATH):
            print("âŒ Image path error! Please check paths.")
            return

        # 1. è¯»å–å¹¶è£å‰ª Patch
        img_bad = Image.open(TEST_IMG_PATH).convert("RGB")
        img_good = Image.open(NORMAL_IMG_PATH).convert("RGB")
        
        box = (CROP_X, CROP_Y, CROP_X + PATCH_SIZE, CROP_Y + PATCH_SIZE)
        patch_bad = img_bad.crop(box)
        patch_good = img_good.crop(box)

        # 2. CLIP å¯¹æ¯”
        clip_feat_bad = self.get_feature(patch_bad, 'clip')
        clip_feat_good = self.get_feature(patch_good, 'clip')
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ (ç‚¹ç§¯)
        clip_score = np.dot(clip_feat_bad, clip_feat_good)

        # 3. DINOv2 å¯¹æ¯”
        dino_feat_bad = self.get_feature(patch_bad, 'dino')
        dino_feat_good = self.get_feature(patch_good, 'dino')
        dino_score = np.dot(dino_feat_bad, dino_feat_good)

        # 4. æ‰“å°ç»“æœ
        print("\n" + "="*40)
        print(f"ğŸ“Š Model Comparison Report")
        print("="*40)
        print(f"Defect Patch vs Normal Patch Similarity:")
        print(f"ğŸ”¹ CLIP Score:   {clip_score:.4f}  (Higher = More Similar)")
        print(f"ğŸ”¸ DINOv2 Score: {dino_score:.4f}")
        print("-" * 40)
        
        if clip_score > 0.9 and dino_score < 0.8:
            print("âœ… ç»“è®º: DINOv2 æˆåŠŸå‘ç°äº†å·®å¼‚ï¼Œè€Œ CLIP 'çäº†'ã€‚")
            print("   (DINOv2 åˆ†æ•°ä½è¯´æ˜å®ƒçœ‹å‡ºäº†ä¸¤è€…ä¸åŒï¼Œè¿™æ˜¯å¥½äº‹ï¼)")
        elif clip_score > 0.9 and dino_score > 0.9:
            print("âš ï¸ ç»“è®º: ä¸¤ä¸ªæ¨¡å‹éƒ½æ²¡çœ‹å‡ºåŒºåˆ«ã€‚å¯èƒ½ Patch ä½ç½®æ²¡åˆ‡å‡†ï¼Œæˆ–ç¼ºé™·å¤ªä¸æ˜æ˜¾ã€‚")
        else:
            print("â„¹ï¸ ç»“è®º: è§‚å¯Ÿåˆ†æ•°å·®è·ã€‚é€šå¸¸ DINOv2 çš„åˆ†æ•°åº”è¯¥æ˜¾è‘—ä½äº CLIPã€‚")

        # 5. å¯è§†åŒ–ç¡®è®¤
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.imshow(patch_bad)
        plt.title(f"Defect Patch\n(Test Image)")
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(patch_good)
        plt.title(f"Normal Reference\n(Train Image)")
        plt.axis('off')
        
        plt.tight_layout()
        plt.savefig("comparison_visual.png")
        print("ğŸ–¼ï¸ Patches saved to 'comparison_visual.png'. Check if they look different.")

if __name__ == "__main__":
    comp = ModelComparator()
    comp.run_comparison()
