"""
# æ–‡ä»¶è¯´æ˜ï¼ˆclip/inject_negatives_dino.pyï¼‰

- **æ–‡ä»¶ä½œç”¨**ï¼šä¸ `inject_negatives.py` ç±»ä¼¼ï¼Œä¸º CLIP å‘é‡åº“æ³¨å…¥ CutPaste ä¼ªç¼ºé™·ï¼Œä½†å¢åŠ äº†ç‰¹å¾ç»´åº¦ä¸€è‡´æ€§æ£€æŸ¥ã€‚
- **è¿è¡Œæ–¹å¼**ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ `python Scripts/clip/inject_negatives_dino.py`ï¼Œé€‚ç”¨äºå·²ç»å­˜åœ¨ `embeddings/` çš„åœºæ™¯ã€‚
- **è¾“å‡ºç»“æœ**ï¼šåœ¨ `embeddings/` ç›®å½•ä¸‹çš„ Patch ç´¢å¼•ä¸­è¿½åŠ  `type='synthetic'` çš„è´Ÿæ ·æœ¬ Patchã€‚
- **åˆ†ç±»è§’è‰²**ï¼šå½’å±äº `clip` åˆ†ç±»ï¼Œæ˜¯ CLIP ç®¡çº¿çš„ã€Œå¢å¼ºç‰ˆè´Ÿæ ·æœ¬æ³¨å…¥ã€è„šæœ¬ã€‚
"""

import os
import clip
import torch
import faiss
import pickle
import numpy as np
import random
from PIL import Image, ImageEnhance, ImageOps
from tqdm import tqdm

# --- é…ç½® (å¿…é¡»ä¸ä½  build_visual_bank.py ä¿æŒä¸€è‡´) ---
DATASET_ROOT = "/data/XL/å¤šæ¨¡æ€RAG/DataSet/MVTec-AD"
EMBEDDING_DIR = "./embeddings"  # ä¸æ„å»ºç´¢å¼•çš„ç›®å½•ä¿æŒä¸€è‡´
MODEL_NAME = "ViT-L/14@336px"
STRIDE_RATIO = 0.5
SYNTHETIC_RATIO = 0.5  # æ¯2å¼ æ­£å¸¸å›¾ï¼Œå°±ç”Ÿæˆ1å¼ å›¾é‡çš„â€œå‡ç¼ºé™·â€

class NegativeInjector:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸš€ Loading CLIP ({MODEL_NAME}) on {self.device}...")
        self.model, self.preprocess = clip.load(MODEL_NAME, device=self.device)
        self.input_size = self.model.visual.input_resolution
        self.stride = int(self.input_size * STRIDE_RATIO)

    def generate_synthetic_defect(self, img_pil):
        """æ ¸å¿ƒï¼šCutPaste åˆ¶é€ äººé€ ç¼ºé™·"""
        w, h = img_pil.size
        # 1. éšæœºåˆ‡ä¸€ä¸ªå° Patch (5%-15% å°ºå¯¸)
        patch_w = random.randint(int(w*0.05), int(w*0.15))
        patch_h = random.randint(int(h*0.05), int(h*0.15))
        
        src_x = random.randint(0, w - patch_w)
        src_y = random.randint(0, h - patch_h)
        patch = img_pil.crop((src_x, src_y, src_x + patch_w, src_y + patch_h))
        
        # 2. åæ ·å¢å¼º (å˜è‰²ã€å˜äº®ã€è‰²è°ƒåˆ†ç¦»ï¼Œæ¨¡æ‹Ÿå¼‚ç‰©/åˆ’ç—•)
        if random.random() > 0.5: patch = ImageOps.posterize(patch, 4)
        patch = ImageEnhance.Color(patch).enhance(random.uniform(0.5, 2.5))
        patch = ImageEnhance.Brightness(patch).enhance(random.uniform(0.6, 1.4))
        
        # 3. è´´å›å» (éšæœºä½ç½®)
        dst_x = random.randint(0, w - patch_w)
        dst_y = random.randint(0, h - patch_h)
        aug_img = img_pil.copy()
        aug_img.paste(patch, (dst_x, dst_y))
        
        return aug_img

    def process_category(self, category):
        print(f"\nâš¡ Injecting Negatives for: {category}")
        
        patch_index_path = os.path.join(EMBEDDING_DIR, f"{category}_patch.index")
        meta_path = os.path.join(EMBEDDING_DIR, f"{category}_meta.pkl")
        
        if not os.path.exists(patch_index_path):
            return

        # 1. åŠ è½½ç°æœ‰ç´¢å¼•
        index = faiss.read_index(patch_index_path)
        with open(meta_path, 'rb') as f:
            meta_data = pickle.load(f) # æ ¼å¼: {'global_paths': [], 'patch_info': []}
        
        print(f"   -> Original Size: {index.ntotal}")

        # 2. æ‰«æå¹¶ç”Ÿæˆ
        train_good_path = os.path.join(DATASET_ROOT, category, "train", "good")
        img_files = [f for f in os.listdir(train_good_path) if f.lower().endswith(('.png', '.jpg'))]
        
        new_vectors = []
        new_patch_meta = []
        
        for img_idx, img_file in enumerate(tqdm(img_files, desc="Generating Synthetics")):
            if random.random() > SYNTHETIC_RATIO: continue # æŒ‰æ¯”ä¾‹æŠ½æ ·
            
            img_path = os.path.join(train_good_path, img_file)
            try:
                pil_img = Image.open(img_path).convert("RGB")
                bad_img = self.generate_synthetic_defect(pil_img) # é€ å‡
                
                # åˆ‡ç‰‡å¹¶æå–ç‰¹å¾
                w, h = bad_img.size
                batch_patches = []
                batch_coords = []
                
                for y in range(0, h - self.input_size + 1, self.stride):
                    for x in range(0, w - self.input_size + 1, self.stride):
                        box = (x, y, x + self.input_size, y + self.input_size)
                        patch = self.preprocess(bad_img.crop(box))
                        batch_patches.append(patch)
                        batch_coords.append((x, y))
                
                if batch_patches:
                    tensor = torch.stack(batch_patches).to(self.device)
                    with torch.no_grad():
                        feats = self.model.encode_image(tensor)
                        feats /= feats.norm(dim=-1, keepdim=True)
                    
                    new_vectors.append(feats.cpu().numpy())
                    
                    # è®°å½•å…ƒæ•°æ®ï¼Œå…³é”®æ˜¯ type='synthetic'
                    for (x, y) in batch_coords:
                        new_patch_meta.append({
                            "parent_idx": -1, # è´Ÿæ ·æœ¬ä¸å…³è”å…·ä½“Globalå›¾
                            "coords": (x, y),
                            "type": "synthetic" 
                        })
            except Exception as e:
                print(f"Error: {e}")

        if not new_vectors:
            return

        # 3. è¿½åŠ å¹¶ä¿å­˜
        final_vectors = np.concatenate(new_vectors, axis=0).astype('float32')
        if final_vectors.shape[1] != index.d:
            raise ValueError(f"Embedding dim mismatch: vectors {final_vectors.shape[1]} vs index {index.d}. è¯·ç¡®ä¿æ¨¡å‹ä¸ç´¢å¼•æ¥æºä¸€è‡´")
        index.add(final_vectors)
        
        # ç»™æ—§æ•°æ®è¡¥ä¸Š type æ ‡è®°
        for item in meta_data['patch_info']:
            if 'type' not in item: item['type'] = 'normal'
            
        meta_data['patch_info'].extend(new_patch_meta)
        
        faiss.write_index(index, patch_index_path)
        with open(meta_path, 'wb') as f:
            pickle.dump(meta_data, f)
            
        print(f"âœ… Added {len(new_patch_meta)} negative patches. New Size: {index.ntotal}")

if __name__ == "__main__":
    injector = NegativeInjector()
    categories = sorted([d for d in os.listdir(DATASET_ROOT) if os.path.isdir(os.path.join(DATASET_ROOT, d))])
    for cat in categories:
        injector.process_category(cat)
