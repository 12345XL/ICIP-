"""
# æ–‡ä»¶è¯´æ˜ï¼ˆclip/inference.pyï¼‰

- **æ–‡ä»¶ä½œç”¨**ï¼šåŸºäº CLIP å‘é‡åº“ï¼Œå¯¹æµ‹è¯•é›†å›¾ç‰‡ç”Ÿæˆå¸¦çƒ­åŠ›å›¾å åŠ çš„å¯è§†åŒ–ç»“æœï¼Œç”¨äºè°ƒè¯• RAG æ€è·¯ã€‚
- **è¿è¡Œæ–¹å¼**ï¼šåœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œ `python Scripts/clip/inference.py`ï¼Œå¯æ ¹æ®éœ€è¦ä¿®æ”¹ `TARGET_CATEGORY`ã€‚
- **è¾“å‡ºç»“æœ**ï¼šåœ¨ `results_visualization_v3/<category>/` ä¸‹ç”Ÿæˆ `[åŸå›¾|å‚ç…§å›¾|çƒ­åŠ›å›¾]` æ‹¼æ¥å›¾ç‰‡ã€‚
- **åˆ†ç±»è§’è‰²**ï¼šå½’å±äº `clip` åˆ†ç±»ï¼Œæ˜¯ CLIP è§†è§‰æ£€ç´¢ç®¡çº¿ä¸­çš„ã€Œæ¨ç†ä¸å¯è§†åŒ–ã€è„šæœ¬ã€‚
"""

import os
import clip
import torch
import faiss
import pickle
import numpy as np
import cv2
from PIL import Image
from tqdm import tqdm
from scipy.ndimage import gaussian_filter

# --- é…ç½® ---
DATASET_ROOT = "/data/XL/å¤šæ¨¡æ€RAG/DataSet/MVTec-AD"
EMBEDDING_DIR = "./embeddings"
OUTPUT_DIR = "./results_visualization_v3" # è¾“å‡ºåˆ°æ–°æ–‡ä»¶å¤¹æ–¹ä¾¿å¯¹æ¯”
MODEL_NAME = "ViT-L/14@336px"
STRIDE_RATIO = 0.5 
TARGET_CATEGORY = "bottle" 

class RAGInference:
    def __init__(self, category):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.category = category
        
        print(f"ğŸš€ Loading CLIP on {self.device}...")
        self.model, self.preprocess = clip.load(MODEL_NAME, device=self.device)
        self.input_size = self.model.visual.input_resolution
        self.stride = int(self.input_size * STRIDE_RATIO)

        print(f"ğŸ“‚ Loading indices for {category}...")
        patch_index_path = os.path.join(EMBEDDING_DIR, f"{category}_patch.index")
        patch_meta_path = os.path.join(EMBEDDING_DIR, f"{category}_meta.pkl")
        
        self.patch_index = faiss.read_index(patch_index_path)
        with open(patch_meta_path, 'rb') as f:
            self.meta = pickle.load(f)
        self.patch_info = self.meta['patch_info']
        
        # Global Index (Optional)
        global_idx_path = os.path.join(EMBEDDING_DIR, f"{category}_global.index")
        if os.path.exists(global_idx_path):
            self.global_index = faiss.read_index(global_idx_path)
            self.global_paths = self.meta.get('global_paths', [])
        else:
            self.global_index = None

    def get_reference_image_path(self, img_feat):
        if self.global_index is None: return None
        D, I = self.global_index.search(img_feat, 1)
        ref_idx = I[0][0]
        if ref_idx < len(self.global_paths):
            return self.global_paths[ref_idx]
        return None

    def compute_anomaly_map(self, img_pil):
        w, h = img_pil.size
        patches = []
        coords = []
        for y in range(0, h - self.input_size + 1, self.stride):
            for x in range(0, w - self.input_size + 1, self.stride):
                box = (x, y, x + self.input_size, y + self.input_size)
                patches.append(self.preprocess(img_pil.crop(box)))
                coords.append((x, y))
        
        if not patches: return None, None

        # 1. æå–ç‰¹å¾
        batch = torch.stack(patches).to(self.device)
        with torch.no_grad():
            feats = self.model.encode_image(batch)
            feats /= feats.norm(dim=-1, keepdim=True)
            feats_np = feats.cpu().numpy().astype('float32')

        # 2. æ£€ç´¢ Top-K (K=5 å–å¹³å‡ï¼Œæ›´ç¨³å¥)
        K = 5
        D, I = self.patch_index.search(feats_np, K)
        
        anomaly_map = np.zeros((h, w), dtype=np.float32)
        count_map = np.zeros((h, w), dtype=np.float32)
        
        for i, (x, y) in enumerate(coords):
            # è®¡ç®—å½“å‰ Patch çš„ Top-K å¹³å‡åˆ†
            k_scores = []
            for k in range(K):
                neighbor_idx = I[i][k]
                similarity = D[i][k] # Cosine Similarity (0-1)
                
                neighbor_type = self.patch_info[neighbor_idx].get('type', 'normal')
                
                # --- æ”¹è¿›åçš„æ‰“åˆ†é€»è¾‘ V3 ---
                if neighbor_type == 'synthetic':
                    # å¦‚æœåŒ¹é…åˆ°åˆæˆç¼ºé™·ï¼Œåˆ†æ•° = ç›¸ä¼¼åº¦ (0.8 ~ 1.0)
                    # è¶Šåƒç¼ºé™·ï¼Œåˆ†è¶Šé«˜
                    score = similarity
                else:
                    # å¦‚æœåŒ¹é…åˆ°æ­£å¸¸æ ·æœ¬ï¼Œåˆ†æ•° = è·ç¦» (0.0 ~ 0.5)
                    # è¶Šåƒæ­£å¸¸ï¼Œåˆ†è¶Šä½
                    score = 1.0 - similarity
                
                k_scores.append(score)
            
            # å–å¹³å‡ (Smooth out noise)
            avg_score = np.mean(k_scores)
            
            # å åŠ 
            anomaly_map[y:y+self.input_size, x:x+self.input_size] += avg_score
            count_map[y:y+self.input_size, x:x+self.input_size] += 1
            
        count_map[count_map == 0] = 1
        anomaly_map /= count_map
        
        # 3. é«˜æ–¯å¹³æ»‘
        anomaly_map = gaussian_filter(anomaly_map, sigma=6) # ç¨å¾®åŠ å¤§å¹³æ»‘åŠ›åº¦
        
        return anomaly_map, feats_np

    def apply_adaptive_threshold(self, heatmap):
        """æ ¸å¿ƒæ”¹è¿›ï¼šOtsu è‡ªé€‚åº”é˜ˆå€¼å»å™ª"""
        # å½’ä¸€åŒ–åˆ° 0-255
        hm_min, hm_max = heatmap.min(), heatmap.max()
        if hm_max == hm_min: return heatmap # é¿å…é™¤é›¶
        
        hm_norm = (heatmap - hm_min) / (hm_max - hm_min)
        hm_uint8 = (hm_norm * 255).astype(np.uint8)
        
        # ä½¿ç”¨ Otsu ç®—æ³•è‡ªåŠ¨å¯»æ‰¾æœ€ä½³é˜ˆå€¼
        # Otsu ä¼šå¯»æ‰¾ä¸€ä¸ªé˜ˆå€¼ï¼Œæœ€å¤§åŒ–ç±»é—´æ–¹å·®ï¼ˆèƒŒæ™¯ vs å‰æ™¯ï¼‰
        otsu_thresh, _ = cv2.threshold(hm_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # --- å…³é”®ç­–ç•¥ ---
        # Otsu æœ‰æ—¶å¯¹åªæœ‰èƒŒæ™¯çš„å›¾ä¹Ÿä¼šåˆ‡å‡ºä¸€åŠä½œä¸ºå‰æ™¯ã€‚
        # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªä¿æŠ¤æœºåˆ¶ï¼šå¦‚æœå…¨å›¾åˆ†æ•°éƒ½å¾ˆä½ï¼Œè¯´æ˜å…¨æ˜¯å¥½å›¾ï¼Œå¼ºåˆ¶å½’é›¶ã€‚
        if hm_max < 0.25: # ç»å¯¹å®‰å…¨é˜ˆå€¼
            return np.zeros_like(heatmap)
            
        # å°†ä½äº Otsu é˜ˆå€¼çš„åŒºåŸŸå¼ºåˆ¶å½’é›¶ (èƒŒæ™¯æŠ‘åˆ¶)
        # å°†é˜ˆå€¼è½¬å› 0-1 èŒƒå›´
        thresh_val = otsu_thresh / 255.0
        
        # è½¯æˆªæ–­ï¼šä½äºé˜ˆå€¼çš„ç¼“æ…¢è¡°å‡ï¼Œé«˜äºé˜ˆå€¼çš„ä¿ç•™
        # è¿™é‡Œä½¿ç”¨ç¡¬æˆªæ–­æµ‹è¯•æ•ˆæœï¼Œå¦‚æœå¤ªç”Ÿç¡¬å¯ä»¥æ”¹å›è½¯æˆªæ–­
        cleaned_map = heatmap.copy()
        cleaned_map[hm_norm < thresh_val] = 0
        
        return cleaned_map

    def visualize(self, img_path, ref_path, heatmap, save_name):
        img = cv2.imread(img_path)
        img = cv2.resize(img, (512, 512))
        
        if ref_path and os.path.exists(ref_path):
            ref = cv2.imread(ref_path)
            ref = cv2.resize(ref, (512, 512))
        else:
            ref = np.zeros_like(img)
            
        # --- ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼å¤„ç†çƒ­åŠ›å›¾ ---
        heatmap = self.apply_adaptive_threshold(heatmap)
        # è°ƒæ•´çƒ­åŠ›å›¾åˆ°ä¸æ˜¾ç¤ºå°ºå¯¸ä¸€è‡´ï¼Œé¿å…å¸ƒå°”æ©ç ä¸å›¾åƒå°ºå¯¸ä¸åŒ¹é…
        heatmap = cv2.resize(heatmap, (512, 512), interpolation=cv2.INTER_LINEAR)
        
        # é‡æ–°å½’ä¸€åŒ–ä»¥ä¾¿å¯è§†åŒ–
        hm_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
        hm_uint8 = np.uint8(255 * hm_norm)
        hm_color = cv2.applyColorMap(hm_uint8, cv2.COLORMAP_JET)
        
        # å¦‚æœçƒ­åŠ›å›¾æ˜¯å…¨0 (å®Œç¾å¥½å›¾)ï¼Œä¸è¦å åŠ è“è‰²ï¼Œç›´æ¥æ˜¾ç¤ºåŸå›¾
        if heatmap.max() == 0:
            overlay = img
        else:
            # ä»…åœ¨éé›¶åŒºåŸŸå åŠ é¢œè‰²
            mask = hm_norm > 0.05
            blended = cv2.addWeighted(img, 0.6, hm_color, 0.4, 0)
            overlay = img.copy()
            overlay[mask] = blended[mask]
        
        concat = np.hstack((img, ref, overlay))
        cv2.imwrite(save_name, concat)

    def run_test(self):
        test_root = os.path.join(DATASET_ROOT, self.category, "test")
        save_dir = os.path.join(OUTPUT_DIR, self.category)
        os.makedirs(save_dir, exist_ok=True)
        
        subdirs = [d for d in os.listdir(test_root) if os.path.isdir(os.path.join(test_root, d))]
        
        for dtype in subdirs:
            img_dir = os.path.join(test_root, dtype)
            files = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg'))][:3]
            
            for f in tqdm(files, desc=f"Infering {dtype}"):
                img_path = os.path.join(img_dir, f)
                pil_img = Image.open(img_path).convert("RGB")
                
                heatmap, patch_feats = self.compute_anomaly_map(pil_img)
                if heatmap is None: continue
                
                # æ‰¾å‚ç…§
                global_feat_approx = np.mean(patch_feats, axis=0, keepdims=True)
                global_feat_approx /= np.linalg.norm(global_feat_approx)
                ref_path = self.get_reference_image_path(global_feat_approx)
                
                save_name = os.path.join(save_dir, f"{dtype}_{f}")
                self.visualize(img_path, ref_path, heatmap, save_name)

if __name__ == "__main__":
    engine = RAGInference(category="bottle")
    engine.run_test()
    print(f"\nâœ… Inference Complete! Results saved to {OUTPUT_DIR}")
